{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9879241,"sourceType":"datasetVersion","datasetId":6065521}],"dockerImageVersionId":30827,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, Embedding, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport matplotlib.pyplot as plt\nimport os\n\n# Load the dataset /kaggle/input/fashion-product-text-images-dataset\nDATA_PATH = \"../input/fashion-product-text-images-dataset\"\nCSV_FILE = os.path.join(DATA_PATH, \"data.csv\")\nIMAGE_PATH = os.path.join(DATA_PATH, \"data\")\n\ndata = pd.read_csv(CSV_FILE)\n\n# Preview the dataset\ndata.dropna(subset=[\"image\", \"description\", \"category\"], inplace=True)\nprint(\"Dataset Preview:\")\nprint(data.head())\n\n# Encode the categories\nlabel_encoder = LabelEncoder()\ndata['category_encoded'] = label_encoder.fit_transform(data['category'])\n\n# Split the data\ntrain_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n\n# Preprocessing for images\ndef preprocess_image(img_path):\n    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\n    img = tf.keras.preprocessing.image.img_to_array(img)\n    img = tf.keras.applications.efficientnet.preprocess_input(img)\n    return img\n\ndef load_images(df):\n    images = []\n    for img_name in df['image']:\n        img_path = os.path.join(IMAGE_PATH, img_name)\n        images.append(preprocess_image(img_path))\n    return np.array(images)\n\ntrain_images = load_images(train_data)\nval_images = load_images(val_data)\n\n# Preprocessing for text\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nMAX_LEN = 100\nMAX_WORDS = 10000\ntokenizer = Tokenizer(num_words=MAX_WORDS)\ntokenizer.fit_on_texts(train_data['description'])\n\ntrain_text = tokenizer.texts_to_sequences(train_data['description'])\nval_text = tokenizer.texts_to_sequences(val_data['description'])\n\ntrain_text = pad_sequences(train_text, maxlen=MAX_LEN)\nval_text = pad_sequences(val_text, maxlen=MAX_LEN)\n\n# Normalize the target\nscaler = StandardScaler()\ntrain_labels = tf.keras.utils.to_categorical(train_data['category_encoded'])\nval_labels = tf.keras.utils.to_categorical(val_data['category_encoded'])\n\n# Build the image model\nimage_input = Input(shape=(224, 224, 3), name=\"image_input\")\nbase_model = EfficientNetB0(include_top=False, input_tensor=image_input)\nimage_features = GlobalAveragePooling2D()(base_model.output)\nimage_features = Dropout(0.3)(image_features)\n\n# Build the text model\ntext_input = Input(shape=(MAX_LEN,), name=\"text_input\")\nembedding = Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=MAX_LEN)(text_input)\ntext_features = tf.keras.layers.LSTM(128)(embedding)\ntext_features = Dropout(0.3)(text_features)\n\n# Multimodal fusion\nmerged = Concatenate()([image_features, text_features])\noutput = Dense(len(label_encoder.classes_), activation=\"softmax\", name=\"output\")(merged)\n\n# Define the model\nmodel = Model(inputs=[image_input, text_input], outputs=output)\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n              loss=\"categorical_crossentropy\", \n              metrics=[\"accuracy\"])\n\n# Model summary\nmodel.summary()\n\n# Train the model\nhistory = model.fit(\n    [train_images, train_text], train_labels,\n    validation_data=([val_images, val_text], val_labels),\n    epochs=10,\n    batch_size=32\n)\n\n# Plot results\ndef plot_history(history):\n    plt.figure(figsize=(12, 4))\n\n    # Accuracy plot\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['accuracy'], label='Train Accuracy')\n    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n    plt.title('Accuracy')\n    plt.legend()\n\n    # Loss plot\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Train Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss')\n    plt.legend()\n\n    plt.show()\n\nplot_history(history)\n\n# Save the model\nmodel.save(\"fashion_recommendation_model.h5\")\n","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}